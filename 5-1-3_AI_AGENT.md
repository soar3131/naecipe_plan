# ë‚´ì‹œí”¼(Naecipe) AI ì—ì´ì „íŠ¸ ì•„í‚¤í…ì²˜

> ìƒìœ„ ë¬¸ì„œ: [5-1SERVICE_ARCHITECTURE.md](./5-1SERVICE_ARCHITECTURE.md)

---

## 1. AI Agent ì„œë¹„ìŠ¤ ê°œìš”

### 1.1 ì—ì´ì „íŠ¸ ìœ í˜•

ë‚´ì‹œí”¼ ì„œë¹„ìŠ¤ëŠ” 4ê°€ì§€ í•µì‹¬ AI ì—ì´ì „íŠ¸ë¥¼ ìš´ì˜í•œë‹¤.

```mermaid
flowchart TB
    subgraph AIAgentService["AI Agent Service"]
        subgraph Agents["ì—ì´ì „íŠ¸"]
            ADJ[Adjustment Agent<br/>ë ˆì‹œí”¼ ë³´ì •]
            QA[Q&A Agent<br/>ì¡°ë¦¬ ì§ˆë¬¸ ì‘ë‹µ]
            TAG[Tagging Agent<br/>ìë™ ë¶„ë¥˜]
            CRAWLER[Crawler Agent<br/>ì™¸ë¶€ ë ˆì‹œí”¼ ìˆ˜ì§‘]
        end

        subgraph SharedComponents["ê³µìœ  ì»´í¬ë„ŒíŠ¸"]
            EMB[Embedding Service]
            VECTOR[(Vector Store<br/>pgvector)]
            PROMPT[Prompt Templates]
            MEMORY[Conversation Memory]
        end

        Agents --> SharedComponents
    end

    subgraph ExternalLLM["External LLM"]
        OPENAI[OpenAI GPT-4]
        ANTHROPIC[Anthropic Claude]
    end

    AIAgentService --> ExternalLLM
```

| ì—ì´ì „íŠ¸ | ì—­í•  | íŠ¸ë¦¬ê±° | ì‘ë‹µ ì‹œê°„ ëª©í‘œ |
|---------|------|--------|---------------|
| **Adjustment Agent** | í”¼ë“œë°± ê¸°ë°˜ ë ˆì‹œí”¼ ë³´ì • | FeedbackSubmitted ì´ë²¤íŠ¸ | < 10ì´ˆ |
| **Q&A Agent** | ì¡°ë¦¬ ì¤‘ ì§ˆë¬¸ ì‘ë‹µ | ì‚¬ìš©ì ì§ì ‘ ì§ˆë¬¸ | < 3ì´ˆ |
| **Tagging Agent** | ë ˆì‹œí”¼ ìë™ ë¶„ë¥˜ | ìƒˆ ë ˆì‹œí”¼ ë“±ë¡ | < 5ì´ˆ |
| **Crawler Agent** | ì™¸ë¶€ ë ˆì‹œí”¼ í¬ë¡¤ë§ ë° ì •ê·œí™” | ìŠ¤ì¼€ì¤„ëŸ¬ / ìˆ˜ë™ íŠ¸ë¦¬ê±° | ë ˆì‹œí”¼ë‹¹ < 30ì´ˆ |

---

## 2. Adjustment Agent ìƒì„¸

### 2.1 LangGraph ì›Œí¬í”Œë¡œìš°

```mermaid
flowchart TB
    START((ì‹œì‘)) --> PARSE[í”¼ë“œë°± íŒŒì‹±]

    PARSE --> ANALYZE[í”¼ë“œë°± ë¶„ì„]

    ANALYZE --> RETRIEVE[ê´€ë ¨ ì§€ì‹ ê²€ìƒ‰<br/>RAG]

    RETRIEVE --> DECIDE{ë³´ì • í•„ìš”?}

    DECIDE -->|Yes| PLAN[ë³´ì • ê³„íš ìˆ˜ë¦½]
    DECIDE -->|No| SKIP[ë³´ì • ìŠ¤í‚µ]

    PLAN --> ADJUST[ë ˆì‹œí”¼ ë³´ì • ì‹¤í–‰]

    ADJUST --> VALIDATE{ê²€ì¦ í†µê³¼?}

    VALIDATE -->|Yes| SAVE[ë³´ì •ë³¸ ì €ì¥]
    VALIDATE -->|No| RETRY{ì¬ì‹œë„?}

    RETRY -->|Yes| ADJUST
    RETRY -->|No| FAIL[ì‹¤íŒ¨ ì²˜ë¦¬]

    SAVE --> NOTIFY[ì‚¬ìš©ì ì•Œë¦¼]
    SKIP --> NOTIFY
    FAIL --> NOTIFY

    NOTIFY --> END((ì¢…ë£Œ))

    style START fill:#4caf50
    style END fill:#4caf50
    style FAIL fill:#f44336
```

### 2.2 Adjustment Agent êµ¬í˜„

```python
# adjustment_agent.py

from langgraph.graph import StateGraph, END
from langchain_openai import ChatOpenAI
from langchain_anthropic import ChatAnthropic
from pydantic import BaseModel
from typing import List, Optional, Literal
import json

class FeedbackData(BaseModel):
    taste_rating: int
    difficulty_rating: int
    feedback_text: str
    adjustment_requests: List[dict]

class AdjustmentState(BaseModel):
    # Input
    recipe_id: str
    original_recipe: dict
    feedback: FeedbackData
    user_preferences: dict

    # Processing
    parsed_feedback: Optional[dict] = None
    retrieved_knowledge: Optional[List[dict]] = None
    adjustment_plan: Optional[dict] = None

    # Output
    adjusted_recipe: Optional[dict] = None
    change_summary: Optional[str] = None
    status: Literal["pending", "processing", "completed", "failed"] = "pending"
    error_message: Optional[str] = None

class AdjustmentAgent:
    def __init__(self):
        self.llm = ChatOpenAI(model="gpt-4-turbo-preview", temperature=0.3)
        self.fallback_llm = ChatAnthropic(model="claude-3-sonnet")
        self.graph = self._build_graph()

    def _build_graph(self) -> StateGraph:
        workflow = StateGraph(AdjustmentState)

        # Add nodes
        workflow.add_node("parse_feedback", self.parse_feedback)
        workflow.add_node("analyze_feedback", self.analyze_feedback)
        workflow.add_node("retrieve_knowledge", self.retrieve_knowledge)
        workflow.add_node("plan_adjustment", self.plan_adjustment)
        workflow.add_node("execute_adjustment", self.execute_adjustment)
        workflow.add_node("validate_result", self.validate_result)
        workflow.add_node("save_result", self.save_result)

        # Add edges
        workflow.set_entry_point("parse_feedback")
        workflow.add_edge("parse_feedback", "analyze_feedback")
        workflow.add_edge("analyze_feedback", "retrieve_knowledge")
        workflow.add_edge("retrieve_knowledge", "plan_adjustment")
        workflow.add_conditional_edges(
            "plan_adjustment",
            self.should_adjust,
            {
                "adjust": "execute_adjustment",
                "skip": "save_result"
            }
        )
        workflow.add_edge("execute_adjustment", "validate_result")
        workflow.add_conditional_edges(
            "validate_result",
            self.is_valid,
            {
                "valid": "save_result",
                "invalid": "execute_adjustment",
                "fail": END
            }
        )
        workflow.add_edge("save_result", END)

        return workflow.compile()

    async def parse_feedback(self, state: AdjustmentState) -> dict:
        """í”¼ë“œë°± í…ìŠ¤íŠ¸ë¥¼ êµ¬ì¡°í™”ëœ í˜•íƒœë¡œ íŒŒì‹±"""
        prompt = f"""
        ì‚¬ìš©ì í”¼ë“œë°±ì„ ë¶„ì„í•˜ì—¬ êµ¬ì¡°í™”ëœ í˜•íƒœë¡œ ë°˜í™˜í•˜ì„¸ìš”.

        í”¼ë“œë°±: {state.feedback.feedback_text}
        ë§› í‰ì : {state.feedback.taste_rating}/5
        ë‚œì´ë„ í‰ì : {state.feedback.difficulty_rating}/5
        ìš”ì²­ì‚¬í•­: {json.dumps(state.feedback.adjustment_requests, ensure_ascii=False)}

        ë‹¤ìŒ ì¹´í…Œê³ ë¦¬ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”:
        - taste_issues: ë§› ê´€ë ¨ ë¬¸ì œ (ë„ˆë¬´ ì§œë‹¤, ì‹±ê²ë‹¤, ë§µë‹¤ ë“±)
        - portion_issues: ì–‘ ê´€ë ¨ ë¬¸ì œ (ë„ˆë¬´ ë§ë‹¤, ì ë‹¤)
        - difficulty_issues: ë‚œì´ë„ ê´€ë ¨ (ë„ˆë¬´ ì–´ë µë‹¤, ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦°ë‹¤)
        - ingredient_issues: ì¬ë£Œ ê´€ë ¨ (ëŒ€ì²´ ì¬ë£Œ í•„ìš”, ì¬ë£Œ ë¹¼ê³  ì‹¶ë‹¤)
        - positive_feedback: ê¸ì •ì  í”¼ë“œë°±

        JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•˜ì„¸ìš”.
        """

        response = await self.llm.ainvoke(prompt)
        parsed = json.loads(response.content)

        return {"parsed_feedback": parsed}

    async def retrieve_knowledge(self, state: AdjustmentState) -> dict:
        """ê´€ë ¨ ìš”ë¦¬ ì§€ì‹ ê²€ìƒ‰ (RAG)"""
        # Vector search for relevant cooking knowledge
        query = f"{state.original_recipe['title']} {state.feedback.feedback_text}"

        chunks = await self.vector_store.similarity_search(
            query=query,
            k=5,
            filter={"source_type": ["cooking_tip", "ingredient_info"]}
        )

        return {"retrieved_knowledge": [c.to_dict() for c in chunks]}

    async def execute_adjustment(self, state: AdjustmentState) -> dict:
        """ë ˆì‹œí”¼ ë³´ì • ì‹¤í–‰"""
        prompt = f"""
        ë‹¹ì‹ ì€ ì „ë¬¸ ìš”ë¦¬ì‚¬ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ í”¼ë“œë°±ì„ ë°˜ì˜í•˜ì—¬ ë ˆì‹œí”¼ë¥¼ ë³´ì •í•˜ì„¸ìš”.

        ## ì›ë³¸ ë ˆì‹œí”¼
        {json.dumps(state.original_recipe, ensure_ascii=False, indent=2)}

        ## ì‚¬ìš©ì í”¼ë“œë°± ë¶„ì„
        {json.dumps(state.parsed_feedback, ensure_ascii=False, indent=2)}

        ## ì‚¬ìš©ì ì·¨í–¥
        {json.dumps(state.user_preferences, ensure_ascii=False, indent=2)}

        ## ë³´ì • ê³„íš
        {json.dumps(state.adjustment_plan, ensure_ascii=False, indent=2)}

        ## ì°¸ê³  ì§€ì‹
        {json.dumps(state.retrieved_knowledge, ensure_ascii=False, indent=2)}

        ## ë³´ì • ê·œì¹™
        1. ì›ë³¸ ë ˆì‹œí”¼ì˜ êµ¬ì¡°ë¥¼ ìœ ì§€í•˜ë©´ì„œ í•„ìš”í•œ ë¶€ë¶„ë§Œ ìˆ˜ì •
        2. ë³€ê²½ ì‚¬í•­ì€ ëª…í™•í•˜ê²Œ í‘œì‹œ
        3. ì‹¤í˜„ ê°€ëŠ¥í•œ ë²”ìœ„ ë‚´ì—ì„œë§Œ ìˆ˜ì •
        4. ì‚¬ìš©ì ì·¨í–¥(ë§› ì„ í˜¸ë„, ì•Œë ˆë¥´ê¸° ë“±)ì„ ë°˜ë“œì‹œ ê³ ë ¤

        ë³´ì •ëœ ë ˆì‹œí”¼ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•˜ì„¸ìš”.
        ë³€ê²½ëœ ë¶€ë¶„ì—ëŠ” "adjusted": true í”Œë˜ê·¸ë¥¼ ì¶”ê°€í•˜ì„¸ìš”.
        """

        try:
            response = await self.llm.ainvoke(prompt)
            adjusted = json.loads(response.content)
            return {"adjusted_recipe": adjusted, "status": "processing"}
        except Exception as e:
            # Fallback to Claude
            response = await self.fallback_llm.ainvoke(prompt)
            adjusted = json.loads(response.content)
            return {"adjusted_recipe": adjusted, "status": "processing"}

    def should_adjust(self, state: AdjustmentState) -> str:
        """ë³´ì • í•„ìš” ì—¬ë¶€ íŒë‹¨"""
        if not state.adjustment_plan or not state.adjustment_plan.get("adjustments"):
            return "skip"
        return "adjust"

    def is_valid(self, state: AdjustmentState) -> str:
        """ë³´ì • ê²°ê³¼ ê²€ì¦"""
        if not state.adjusted_recipe:
            return "fail"

        # Validate structure
        required_fields = ["title", "ingredients", "steps"]
        for field in required_fields:
            if field not in state.adjusted_recipe:
                return "invalid"

        return "valid"

    async def run(self, input_data: dict) -> AdjustmentState:
        """ì—ì´ì „íŠ¸ ì‹¤í–‰"""
        initial_state = AdjustmentState(**input_data)
        final_state = await self.graph.ainvoke(initial_state)
        return final_state
```

---

## 3. Q&A Agent ìƒì„¸

### 3.1 Q&A Agent ì›Œí¬í”Œë¡œìš°

```mermaid
flowchart TB
    START((ì‹œì‘)) --> RECEIVE[ì§ˆë¬¸ ìˆ˜ì‹ ]

    RECEIVE --> CLASSIFY{ì§ˆë¬¸ ë¶„ë¥˜}

    CLASSIFY -->|ë ˆì‹œí”¼ ê´€ë ¨| RECIPE_CONTEXT[ë ˆì‹œí”¼ ì»¨í…ìŠ¤íŠ¸ ë¡œë“œ]
    CLASSIFY -->|ì¼ë°˜ ìš”ë¦¬| GENERAL_CONTEXT[ì¼ë°˜ ì§€ì‹ ê²€ìƒ‰]
    CLASSIFY -->|ëŒ€ì²´ ì¬ë£Œ| SUBSTITUTE_CONTEXT[ëŒ€ì²´ ì¬ë£Œ ê²€ìƒ‰]
    CLASSIFY -->|ì¡°ë¦¬ íŒ| TIP_CONTEXT[ì¡°ë¦¬ íŒ ê²€ìƒ‰]

    RECIPE_CONTEXT --> RETRIEVE[RAG ê²€ìƒ‰]
    GENERAL_CONTEXT --> RETRIEVE
    SUBSTITUTE_CONTEXT --> RETRIEVE
    TIP_CONTEXT --> RETRIEVE

    RETRIEVE --> GENERATE[ë‹µë³€ ìƒì„±]

    GENERATE --> FORMAT[ë‹µë³€ í¬ë§·íŒ…]

    FORMAT --> SAVE_HISTORY[ëŒ€í™” ê¸°ë¡ ì €ì¥]

    SAVE_HISTORY --> RESPOND[ì‘ë‹µ ë°˜í™˜]

    RESPOND --> END((ì¢…ë£Œ))

    style START fill:#4caf50
    style END fill:#4caf50
```

### 3.2 Q&A Agent êµ¬í˜„

```python
# qa_agent.py

from langgraph.graph import StateGraph, END
from langchain_openai import ChatOpenAI
from pydantic import BaseModel
from typing import List, Optional, Literal

class QAState(BaseModel):
    # Input
    user_id: str
    session_id: str
    question: str
    recipe_context: Optional[dict] = None  # í˜„ì¬ ì¡°ë¦¬ ì¤‘ì¸ ë ˆì‹œí”¼

    # Processing
    question_type: Optional[str] = None
    retrieved_chunks: Optional[List[dict]] = None
    conversation_history: List[dict] = []

    # Output
    answer: Optional[str] = None
    sources: Optional[List[str]] = None
    follow_up_suggestions: Optional[List[str]] = None

class QAAgent:
    def __init__(self):
        self.llm = ChatOpenAI(model="gpt-4-turbo-preview", temperature=0.5)
        self.graph = self._build_graph()

    def _build_graph(self) -> StateGraph:
        workflow = StateGraph(QAState)

        workflow.add_node("classify_question", self.classify_question)
        workflow.add_node("retrieve_context", self.retrieve_context)
        workflow.add_node("generate_answer", self.generate_answer)
        workflow.add_node("format_response", self.format_response)

        workflow.set_entry_point("classify_question")
        workflow.add_edge("classify_question", "retrieve_context")
        workflow.add_edge("retrieve_context", "generate_answer")
        workflow.add_edge("generate_answer", "format_response")
        workflow.add_edge("format_response", END)

        return workflow.compile()

    async def classify_question(self, state: QAState) -> dict:
        """ì§ˆë¬¸ ìœ í˜• ë¶„ë¥˜"""
        prompt = f"""
        ë‹¤ìŒ ìš”ë¦¬ ê´€ë ¨ ì§ˆë¬¸ì˜ ìœ í˜•ì„ ë¶„ë¥˜í•˜ì„¸ìš”.

        ì§ˆë¬¸: {state.question}

        ìœ í˜•:
        - recipe_specific: í˜„ì¬ ë ˆì‹œí”¼ì— ëŒ€í•œ êµ¬ì²´ì  ì§ˆë¬¸
        - technique: ì¡°ë¦¬ ê¸°ìˆ /ë°©ë²• ì§ˆë¬¸
        - substitute: ì¬ë£Œ ëŒ€ì²´ ì§ˆë¬¸
        - timing: ì¡°ë¦¬ ì‹œê°„/íƒ€ì´ë° ì§ˆë¬¸
        - troubleshooting: ë¬¸ì œ í•´ê²° ì§ˆë¬¸
        - general: ì¼ë°˜ ìš”ë¦¬ ì§€ì‹

        ìœ í˜•ë§Œ ë°˜í™˜í•˜ì„¸ìš”.
        """

        response = await self.llm.ainvoke(prompt)
        return {"question_type": response.content.strip()}

    async def retrieve_context(self, state: QAState) -> dict:
        """ê´€ë ¨ ì§€ì‹ ê²€ìƒ‰"""
        # Build search query based on question type
        if state.recipe_context:
            query = f"{state.recipe_context['title']} {state.question}"
        else:
            query = state.question

        # Filter based on question type
        filters = {
            "technique": ["cooking_technique", "cooking_tip"],
            "substitute": ["ingredient_substitute", "ingredient_info"],
            "timing": ["cooking_tip", "recipe"],
            "troubleshooting": ["cooking_tip", "troubleshooting"],
        }

        source_filter = filters.get(state.question_type, None)

        chunks = await self.vector_store.similarity_search(
            query=query,
            k=5,
            filter={"source_type": source_filter} if source_filter else None
        )

        return {"retrieved_chunks": [c.to_dict() for c in chunks]}

    async def generate_answer(self, state: QAState) -> dict:
        """ë‹µë³€ ìƒì„±"""
        # Build conversation context
        history = "\n".join([
            f"{'User' if m['role'] == 'user' else 'Assistant'}: {m['content']}"
            for m in state.conversation_history[-5:]  # Last 5 messages
        ])

        prompt = f"""
        ë‹¹ì‹ ì€ ì¹œì ˆí•˜ê³  ì „ë¬¸ì ì¸ ìš”ë¦¬ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

        ## ëŒ€í™” ê¸°ë¡
        {history}

        ## í˜„ì¬ ì§ˆë¬¸
        {state.question}

        ## í˜„ì¬ ì¡°ë¦¬ ì¤‘ì¸ ë ˆì‹œí”¼
        {json.dumps(state.recipe_context, ensure_ascii=False) if state.recipe_context else "ì—†ìŒ"}

        ## ê´€ë ¨ ì§€ì‹
        {json.dumps(state.retrieved_chunks, ensure_ascii=False)}

        ## ë‹µë³€ ì§€ì¹¨
        1. ê°„ê²°í•˜ê³  ì‹¤ìš©ì ì¸ ë‹µë³€ ì œê³µ
        2. ì•ˆì „ ê´€ë ¨ ì£¼ì˜ì‚¬í•­ì´ ìˆìœ¼ë©´ ë°˜ë“œì‹œ ì–¸ê¸‰
        3. ê°€ëŠ¥í•˜ë©´ êµ¬ì²´ì ì¸ íŒ í¬í•¨
        4. ë¶ˆí™•ì‹¤í•œ ì •ë³´ëŠ” ê·¸ë ‡ë‹¤ê³  ëª…ì‹œ

        ë‹µë³€ì„ ì‘ì„±í•˜ì„¸ìš”.
        """

        response = await self.llm.ainvoke(prompt)

        # Generate follow-up suggestions
        suggestions_prompt = f"""
        ìœ„ ë‹µë³€ í›„ ì‚¬ìš©ìê°€ ê¶ê¸ˆí•´í•  ìˆ˜ ìˆëŠ” í›„ì† ì§ˆë¬¸ 3ê°œë¥¼ ì œì•ˆí•˜ì„¸ìš”.
        ì§§ì€ ì§ˆë¬¸ í˜•íƒœë¡œ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜í•˜ì„¸ìš”.
        """

        suggestions_response = await self.llm.ainvoke(suggestions_prompt)
        suggestions = suggestions_response.content.strip().split("\n")

        return {
            "answer": response.content,
            "follow_up_suggestions": suggestions[:3]
        }

    async def run(self, input_data: dict) -> QAState:
        initial_state = QAState(**input_data)
        final_state = await self.graph.ainvoke(initial_state)
        return final_state
```

---

## 4. Tagging Agent ìƒì„¸

### 4.1 Tagging Agent ì›Œí¬í”Œë¡œìš°

```mermaid
flowchart TB
    START((ì‹œì‘)) --> EXTRACT[ë ˆì‹œí”¼ ì •ë³´ ì¶”ì¶œ]

    EXTRACT --> ANALYZE[ì½˜í…ì¸  ë¶„ì„]

    ANALYZE --> GENERATE_TAGS[íƒœê·¸ ìƒì„±]

    subgraph TagCategories["íƒœê·¸ ì¹´í…Œê³ ë¦¬"]
        CAT1[ìš”ë¦¬ ì¢…ë¥˜<br/>í•œì‹, ì–‘ì‹, ì¤‘ì‹...]
        CAT2[ì‹ì‚¬ ìœ í˜•<br/>ì•„ì¹¨, ì ì‹¬, ì €ë…...]
        CAT3[ì¡°ë¦¬ ë°©ë²•<br/>ë³¶ìŒ, êµ¬ì´, ì°œ...]
        CAT4[ì‹ì´ ì œí•œ<br/>ì±„ì‹, ì €ì—¼, ë¬´ê¸€ë£¨í…...]
        CAT5[ë‚œì´ë„<br/>ì´ˆê¸‰, ì¤‘ê¸‰, ê³ ê¸‰]
        CAT6[ì†Œìš” ì‹œê°„<br/>15ë¶„, 30ë¶„, 1ì‹œê°„...]
    end

    GENERATE_TAGS --> CAT1
    GENERATE_TAGS --> CAT2
    GENERATE_TAGS --> CAT3
    GENERATE_TAGS --> CAT4
    GENERATE_TAGS --> CAT5
    GENERATE_TAGS --> CAT6

    CAT1 --> VALIDATE[íƒœê·¸ ê²€ì¦]
    CAT2 --> VALIDATE
    CAT3 --> VALIDATE
    CAT4 --> VALIDATE
    CAT5 --> VALIDATE
    CAT6 --> VALIDATE

    VALIDATE --> SAVE[íƒœê·¸ ì €ì¥]

    SAVE --> END((ì¢…ë£Œ))

    style START fill:#4caf50
    style END fill:#4caf50
```

---

## 5. Recipe Crawler Agent ìƒì„¸

### 5.1 ê°œìš”

Recipe Crawler AgentëŠ” ì™¸ë¶€ í”Œë«í¼(YouTube, Instagram, ë¸”ë¡œê·¸, ë ˆì‹œí”¼ ì‚¬ì´íŠ¸)ì—ì„œ ìœ ëª… ì‰í”„/ì¸í”Œë£¨ì–¸ì„œì˜ ë ˆì‹œí”¼ë¥¼ ìˆ˜ì§‘í•˜ê³ , LLMì„ í™œìš©í•˜ì—¬ êµ¬ì¡°í™”ëœ í˜•íƒœë¡œ ë³€í™˜í•˜ëŠ” ì—ì´ì „íŠ¸ì´ë‹¤.

**ìš´ì˜ ë°©ì‹:**
- ë¡œì»¬ í™˜ê²½ ë˜ëŠ” ë³„ë„ ì„œë²„ì—ì„œ Botìœ¼ë¡œ ì‹¤í–‰
- ìŠ¤ì¼€ì¤„ëŸ¬ ê¸°ë°˜ ìë™ ì‹¤í–‰ + ìˆ˜ë™ íŠ¸ë¦¬ê±° ì§€ì›
- Ingestion APIë¥¼ í†µí•´ ë°±ì—”ë“œ ì„œë¹„ìŠ¤ì™€ í†µì‹ 

### 5.2 Crawler Agent ì›Œí¬í”Œë¡œìš°

```mermaid
flowchart TB
    START((ì‹œì‘)) --> SCHEDULE[ìŠ¤ì¼€ì¤„ë§/íŠ¸ë¦¬ê±°]

    SCHEDULE --> SELECT_SOURCE[ì†ŒìŠ¤ ì„ íƒ<br/>YouTube/Instagram/Blog]

    SELECT_SOURCE --> DISCOVER[ì¸ê¸° ì½˜í…ì¸  ë°œê²¬<br/>API/í¬ë¡¤ë§]

    DISCOVER --> FILTER{ë ˆì‹œí”¼<br/>ì½˜í…ì¸ ?}

    FILTER -->|No| SKIP[ìŠ¤í‚µ]
    FILTER -->|Yes| EXTRACT[ì½˜í…ì¸  ì¶”ì¶œ]

    EXTRACT --> PARSE[LLM íŒŒì‹±<br/>ë ˆì‹œí”¼ êµ¬ì¡°í™”]

    PARSE --> NORMALIZE[ë°ì´í„° ì •ê·œí™”<br/>í‘œì¤€ í¬ë§· ë³€í™˜]

    NORMALIZE --> CHECK_DUP{ì¤‘ë³µ ê²€ì‚¬<br/>(ë¡œì»¬ ìºì‹œ)}

    CHECK_DUP -->|ì¤‘ë³µ| UPDATE_SCORE[ì ìˆ˜ ê°±ì‹  ìš”ì²­]
    CHECK_DUP -->|ì‹ ê·œ| VALIDATE[ë°ì´í„° ê²€ì¦]

    VALIDATE --> SUBMIT[Ingestion API ì œì¶œ]

    SUBMIT --> API_RESPONSE{API ì‘ë‹µ}

    API_RESPONSE -->|ì„±ê³µ| LOG_SUCCESS[ì„±ê³µ ë¡œê·¸]
    API_RESPONSE -->|ì¤‘ë³µ íŒì •| LOG_DUP[ì¤‘ë³µ ë¡œê·¸]
    API_RESPONSE -->|ì‹¤íŒ¨| RETRY{ì¬ì‹œë„?}

    RETRY -->|Yes| SUBMIT
    RETRY -->|No| LOG_FAIL[ì‹¤íŒ¨ ë¡œê·¸]

    UPDATE_SCORE --> LOG_SUCCESS
    SKIP --> NEXT
    LOG_SUCCESS --> NEXT
    LOG_DUP --> NEXT
    LOG_FAIL --> NEXT

    NEXT{ë‹¤ìŒ<br/>ì½˜í…ì¸ ?}
    NEXT -->|Yes| DISCOVER
    NEXT -->|No| END((ì¢…ë£Œ))

    style START fill:#4caf50
    style END fill:#4caf50
    style LOG_FAIL fill:#f44336
```

### 5.3 Crawler Agent êµ¬í˜„

```python
# crawler_agent.py

from langgraph.graph import StateGraph, END
from langchain_openai import ChatOpenAI
from pydantic import BaseModel
from typing import List, Optional, Literal
from enum import Enum
import hashlib
import httpx

class SourcePlatform(str, Enum):
    YOUTUBE = "youtube"
    INSTAGRAM = "instagram"
    NAVER_BLOG = "naver_blog"
    TISTORY = "tistory"
    RECIPE_SITE = "recipe_site"

class CrawledContent(BaseModel):
    url: str
    platform: SourcePlatform
    title: str
    author_name: str
    author_channel: str
    raw_content: str
    thumbnail_url: Optional[str] = None
    video_url: Optional[str] = None
    metrics: dict = {}  # view_count, like_count, etc.

class ParsedRecipe(BaseModel):
    title: str
    description: str
    author_name: str
    author_channel: str
    ingredients: List[dict]
    steps: List[dict]
    cooking_time_minutes: Optional[int] = None
    servings: Optional[int] = None
    difficulty: Optional[str] = None
    tags: List[str] = []

class CrawlerState(BaseModel):
    # Input
    platform: SourcePlatform
    target_channels: List[str] = []  # íŠ¹ì • ì±„ë„ë§Œ í¬ë¡¤ë§í•  ê²½ìš°

    # Processing
    discovered_contents: List[CrawledContent] = []
    current_content: Optional[CrawledContent] = None
    parsed_recipe: Optional[ParsedRecipe] = None
    content_hash: Optional[str] = None

    # Output
    processed_count: int = 0
    success_count: int = 0
    duplicate_count: int = 0
    failed_count: int = 0
    results: List[dict] = []

class RecipeCrawlerAgent:
    def __init__(self, ingestion_api_url: str):
        self.llm = ChatOpenAI(model="gpt-4-turbo-preview", temperature=0.2)
        self.ingestion_api_url = ingestion_api_url
        self.graph = self._build_graph()

        # í”Œë«í¼ë³„ í¬ë¡¤ëŸ¬
        self.crawlers = {
            SourcePlatform.YOUTUBE: YouTubeCrawler(),
            SourcePlatform.INSTAGRAM: InstagramCrawler(),
            SourcePlatform.NAVER_BLOG: NaverBlogCrawler(),
        }

    def _build_graph(self) -> StateGraph:
        workflow = StateGraph(CrawlerState)

        workflow.add_node("discover_content", self.discover_content)
        workflow.add_node("extract_content", self.extract_content)
        workflow.add_node("parse_recipe", self.parse_recipe)
        workflow.add_node("check_duplicate", self.check_duplicate)
        workflow.add_node("submit_to_api", self.submit_to_api)
        workflow.add_node("update_score", self.update_score)

        workflow.set_entry_point("discover_content")
        workflow.add_edge("discover_content", "extract_content")
        workflow.add_edge("extract_content", "parse_recipe")
        workflow.add_edge("parse_recipe", "check_duplicate")

        workflow.add_conditional_edges(
            "check_duplicate",
            self.route_after_duplicate_check,
            {
                "new": "submit_to_api",
                "duplicate": "update_score",
                "skip": END
            }
        )

        workflow.add_edge("submit_to_api", END)
        workflow.add_edge("update_score", END)

        return workflow.compile()

    async def parse_recipe(self, state: CrawlerState) -> dict:
        """LLMì„ ì‚¬ìš©í•˜ì—¬ ì›ë³¸ ì½˜í…ì¸ ì—ì„œ ë ˆì‹œí”¼ ì •ë³´ ì¶”ì¶œ"""
        content = state.current_content

        prompt = f"""
        ë‹¤ìŒ ìš”ë¦¬ ì½˜í…ì¸ ì—ì„œ ë ˆì‹œí”¼ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.

        ## ì›ë³¸ ì½˜í…ì¸ 
        ì œëª©: {content.title}
        ì €ì: {content.author_name}
        í”Œë«í¼: {content.platform}

        ë‚´ìš©:
        {content.raw_content[:4000]}  # í† í° ì œí•œ

        ## ì¶”ì¶œí•  ì •ë³´
        1. ìš”ë¦¬ ì œëª© (ì›ë³¸ê³¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ, ì‹¤ì œ ìš”ë¦¬ ì´ë¦„)
        2. ìš”ë¦¬ ì„¤ëª… (1-2ë¬¸ì¥)
        3. ì¬ë£Œ ëª©ë¡ (ì´ë¦„, ì–‘, ë‹¨ìœ„ë¡œ êµ¬ë¶„)
        4. ì¡°ë¦¬ ë‹¨ê³„ (ìˆœì„œ, ì„¤ëª…, ì˜ˆìƒ ì†Œìš”ì‹œê°„)
        5. ì´ ì¡°ë¦¬ ì‹œê°„ (ë¶„)
        6. ì¸ë¶„
        7. ë‚œì´ë„ (easy/medium/hard)
        8. íƒœê·¸ (í•œì‹, ì–‘ì‹, ë°˜ì°¬, ë©”ì¸ìš”ë¦¬ ë“±)

        ## ê·œì¹™
        - ì¬ë£ŒëŠ” ì •í™•í•œ ì–‘ê³¼ ë‹¨ìœ„ë¡œ ë¶„ë¦¬
        - ì¡°ë¦¬ ë‹¨ê³„ëŠ” ëª…í™•í•˜ê³  ì‹¤í–‰ ê°€ëŠ¥í•˜ê²Œ
        - ë¶ˆëª…í™•í•œ ì •ë³´ëŠ” null ë°˜í™˜
        - ë ˆì‹œí”¼ê°€ ì•„ë‹Œ ì½˜í…ì¸ ëŠ” is_recipe: false ë°˜í™˜

        JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•˜ì„¸ìš”.
        """

        response = await self.llm.ainvoke(prompt)
        parsed = json.loads(response.content)

        if not parsed.get('is_recipe', True):
            return {"parsed_recipe": None}

        recipe = ParsedRecipe(
            title=parsed['title'],
            description=parsed.get('description', ''),
            author_name=content.author_name,
            author_channel=content.author_channel,
            ingredients=parsed.get('ingredients', []),
            steps=parsed.get('steps', []),
            cooking_time_minutes=parsed.get('cooking_time_minutes'),
            servings=parsed.get('servings'),
            difficulty=parsed.get('difficulty'),
            tags=parsed.get('tags', [])
        )

        # ì½˜í…ì¸  í•´ì‹œ ìƒì„± (ì¤‘ë³µ ê²€ì‚¬ìš©)
        hash_content = f"{recipe.title}|{recipe.author_name}|{json.dumps(recipe.ingredients)}"
        content_hash = hashlib.sha256(hash_content.encode()).hexdigest()[:32]

        return {
            "parsed_recipe": recipe,
            "content_hash": content_hash
        }

    async def check_duplicate(self, state: CrawlerState) -> dict:
        """Ingestion APIì— ì¤‘ë³µ ê²€ì‚¬ ìš”ì²­"""
        if not state.parsed_recipe:
            return {"is_duplicate": None}

        async with httpx.AsyncClient() as client:
            response = await client.post(
                f"{self.ingestion_api_url}/check-duplicate",
                json={
                    "title": state.parsed_recipe.title,
                    "author_name": state.parsed_recipe.author_name,
                    "content_hash": state.content_hash,
                    "source_url": state.current_content.url
                }
            )

        result = response.json()
        return {
            "is_duplicate": result.get('is_duplicate', False),
            "existing_recipe_id": result.get('recipe_id')
        }

    def route_after_duplicate_check(self, state: CrawlerState) -> str:
        """ì¤‘ë³µ ê²€ì‚¬ ê²°ê³¼ì— ë”°ë¥¸ ë¼ìš°íŒ…"""
        if not state.parsed_recipe:
            return "skip"
        if hasattr(state, 'is_duplicate') and state.is_duplicate:
            return "duplicate"
        return "new"

    async def submit_to_api(self, state: CrawlerState) -> dict:
        """ì‹ ê·œ ë ˆì‹œí”¼ë¥¼ Ingestion APIì— ì œì¶œ"""
        recipe = state.parsed_recipe
        content = state.current_content

        payload = {
            "title": recipe.title,
            "description": recipe.description,
            "author_name": recipe.author_name,
            "author_channel": recipe.author_channel,
            "source_url": content.url,
            "source_platform": content.platform.value,
            "ingredients": recipe.ingredients,
            "steps": recipe.steps,
            "cooking_time_minutes": recipe.cooking_time_minutes,
            "servings": recipe.servings,
            "difficulty": recipe.difficulty,
            "tags": recipe.tags,
            "thumbnail_url": content.thumbnail_url,
            "video_url": content.video_url,
            "content_hash": state.content_hash,
            "source_metrics": content.metrics
        }

        async with httpx.AsyncClient() as client:
            response = await client.post(
                f"{self.ingestion_api_url}/recipes",
                json=payload
            )

        if response.status_code == 201:
            return {
                "success_count": state.success_count + 1,
                "results": state.results + [{"status": "created", "url": content.url}]
            }
        elif response.status_code == 409:  # Conflict - ì¤‘ë³µ
            return {
                "duplicate_count": state.duplicate_count + 1,
                "results": state.results + [{"status": "duplicate", "url": content.url}]
            }
        else:
            return {
                "failed_count": state.failed_count + 1,
                "results": state.results + [{"status": "failed", "url": content.url}]
            }

    async def update_score(self, state: CrawlerState) -> dict:
        """ê¸°ì¡´ ë ˆì‹œí”¼ì˜ ë…¸ì¶œë„/ì¸ê¸°ë„ ì ìˆ˜ ê°±ì‹ """
        content = state.current_content

        async with httpx.AsyncClient() as client:
            await client.patch(
                f"{self.ingestion_api_url}/recipes/{state.existing_recipe_id}/scores",
                json={
                    "source_metrics": content.metrics,
                    "source_url": content.url
                }
            )

        return {
            "duplicate_count": state.duplicate_count + 1,
            "results": state.results + [{"status": "score_updated", "url": content.url}]
        }

    async def run(self, platform: SourcePlatform, channels: List[str] = None) -> CrawlerState:
        """í¬ë¡¤ëŸ¬ ì—ì´ì „íŠ¸ ì‹¤í–‰"""
        initial_state = CrawlerState(
            platform=platform,
            target_channels=channels or []
        )
        final_state = await self.graph.ainvoke(initial_state)
        return final_state
```

### 5.4 í”Œë«í¼ë³„ í¬ë¡¤ëŸ¬ êµ¬í˜„

```python
# crawlers/youtube_crawler.py

from googleapiclient.discovery import build
from typing import List
import re

class YouTubeCrawler:
    """YouTube ë ˆì‹œí”¼ ì±„ë„ í¬ë¡¤ëŸ¬"""

    # ìœ ëª… ìš”ë¦¬ ì±„ë„ ëª©ë¡
    TARGET_CHANNELS = [
        "ë°±ì¢…ì›ì˜ ìš”ë¦¬ë¹„ì±…",
        "ì¿ í‚¹ ë¡œê·¸",
        "ë§Œê°œì˜ë ˆì‹œí”¼",
        "ìŠˆê°€ë³´ìš¸",
        # ... ë” ë§ì€ ì±„ë„
    ]

    def __init__(self):
        self.youtube = build('youtube', 'v3', developerKey=YOUTUBE_API_KEY)

    async def discover_popular_videos(
        self,
        channel_ids: List[str] = None,
        max_results: int = 50
    ) -> List[dict]:
        """ì¸ê¸° ë ˆì‹œí”¼ ì˜ìƒ ë°œê²¬"""
        videos = []

        for channel_id in (channel_ids or self.TARGET_CHANNELS):
            # ì±„ë„ì˜ ìµœê·¼ ì¸ê¸° ì˜ìƒ ì¡°íšŒ
            request = self.youtube.search().list(
                part="snippet",
                channelId=channel_id,
                order="viewCount",
                maxResults=max_results,
                type="video",
                publishedAfter="2024-01-01T00:00:00Z"
            )
            response = request.execute()

            for item in response.get('items', []):
                video_id = item['id']['videoId']
                snippet = item['snippet']

                # ì˜ìƒ í†µê³„ ì¡°íšŒ
                stats = self._get_video_stats(video_id)

                videos.append({
                    'url': f"https://youtube.com/watch?v={video_id}",
                    'title': snippet['title'],
                    'author_name': snippet['channelTitle'],
                    'author_channel': f"youtube.com/channel/{snippet['channelId']}",
                    'description': snippet['description'],
                    'thumbnail_url': snippet['thumbnails']['high']['url'],
                    'video_url': f"https://youtube.com/watch?v={video_id}",
                    'metrics': {
                        'view_count': int(stats.get('viewCount', 0)),
                        'like_count': int(stats.get('likeCount', 0)),
                        'comment_count': int(stats.get('commentCount', 0))
                    }
                })

        return videos

    async def extract_recipe_content(self, video_url: str) -> str:
        """ì˜ìƒì—ì„œ ë ˆì‹œí”¼ ì½˜í…ì¸  ì¶”ì¶œ (ìë§‰ + ì„¤ëª…)"""
        video_id = self._extract_video_id(video_url)

        # ìë§‰ ê°€ì ¸ì˜¤ê¸°
        captions = await self._get_captions(video_id)

        # ì˜ìƒ ì„¤ëª… ê°€ì ¸ì˜¤ê¸°
        description = await self._get_video_description(video_id)

        return f"""
        [ì˜ìƒ ì„¤ëª…]
        {description}

        [ìë§‰ ë‚´ìš©]
        {captions}
        """
```

### 5.5 í¬ë¡¤ë§ ìŠ¤ì¼€ì¤„ëŸ¬

```python
# scheduler/crawl_scheduler.py

from apscheduler.schedulers.asyncio import AsyncIOScheduler
from apscheduler.triggers.cron import CronTrigger
import logging

logger = logging.getLogger(__name__)

class CrawlScheduler:
    """ë ˆì‹œí”¼ í¬ë¡¤ë§ ìŠ¤ì¼€ì¤„ëŸ¬"""

    def __init__(self, crawler_agent: RecipeCrawlerAgent):
        self.agent = crawler_agent
        self.scheduler = AsyncIOScheduler()

    def setup_schedules(self):
        """í¬ë¡¤ë§ ìŠ¤ì¼€ì¤„ ì„¤ì •"""

        # YouTube: ë§¤ì¼ ìƒˆë²½ 2ì‹œ
        self.scheduler.add_job(
            self._crawl_youtube,
            CronTrigger(hour=2, minute=0),
            id='youtube_daily',
            name='YouTube Daily Crawl'
        )

        # Instagram: ë§¤ì¼ ìƒˆë²½ 3ì‹œ
        self.scheduler.add_job(
            self._crawl_instagram,
            CronTrigger(hour=3, minute=0),
            id='instagram_daily',
            name='Instagram Daily Crawl'
        )

        # ë¸”ë¡œê·¸: ë§¤ì¼ ìƒˆë²½ 4ì‹œ
        self.scheduler.add_job(
            self._crawl_blogs,
            CronTrigger(hour=4, minute=0),
            id='blog_daily',
            name='Blog Daily Crawl'
        )

        # ì ìˆ˜ ê°±ì‹ : ë§¤ì£¼ ì¼ìš”ì¼ ìƒˆë²½ 5ì‹œ
        self.scheduler.add_job(
            self._refresh_scores,
            CronTrigger(day_of_week='sun', hour=5, minute=0),
            id='score_refresh_weekly',
            name='Weekly Score Refresh'
        )

    async def _crawl_youtube(self):
        logger.info("Starting YouTube crawl...")
        result = await self.agent.run(SourcePlatform.YOUTUBE)
        logger.info(f"YouTube crawl complete: {result.success_count} new, {result.duplicate_count} duplicates")

    async def _crawl_instagram(self):
        logger.info("Starting Instagram crawl...")
        result = await self.agent.run(SourcePlatform.INSTAGRAM)
        logger.info(f"Instagram crawl complete: {result.success_count} new, {result.duplicate_count} duplicates")

    async def _crawl_blogs(self):
        logger.info("Starting blog crawl...")
        for platform in [SourcePlatform.NAVER_BLOG, SourcePlatform.TISTORY]:
            result = await self.agent.run(platform)
            logger.info(f"{platform} crawl complete: {result.success_count} new")

    def start(self):
        self.scheduler.start()
        logger.info("Crawl scheduler started")

    def stop(self):
        self.scheduler.shutdown()
        logger.info("Crawl scheduler stopped")
```

### 5.6 í¬ë¡¤ëŸ¬ ë´‡ ì‹¤í–‰

```python
# main.py - Crawler Bot Entry Point

import asyncio
import argparse
from crawler_agent import RecipeCrawlerAgent, SourcePlatform
from scheduler.crawl_scheduler import CrawlScheduler

async def main():
    parser = argparse.ArgumentParser(description='Recipe Crawler Bot')
    parser.add_argument('--mode', choices=['schedule', 'once'], default='schedule')
    parser.add_argument('--platform', choices=['youtube', 'instagram', 'blog', 'all'])
    parser.add_argument('--channels', nargs='*', help='Target channels to crawl')
    args = parser.parse_args()

    agent = RecipeCrawlerAgent(
        ingestion_api_url="https://api.naecipe.com/v1/ingestion"
    )

    if args.mode == 'schedule':
        # ìŠ¤ì¼€ì¤„ëŸ¬ ëª¨ë“œ: ì§€ì†ì ìœ¼ë¡œ ì‹¤í–‰
        scheduler = CrawlScheduler(agent)
        scheduler.setup_schedules()
        scheduler.start()

        try:
            while True:
                await asyncio.sleep(3600)
        except KeyboardInterrupt:
            scheduler.stop()

    else:
        # 1íšŒ ì‹¤í–‰ ëª¨ë“œ
        platform_map = {
            'youtube': SourcePlatform.YOUTUBE,
            'instagram': SourcePlatform.INSTAGRAM,
            'blog': SourcePlatform.NAVER_BLOG,
        }

        if args.platform == 'all':
            for platform in platform_map.values():
                result = await agent.run(platform, args.channels)
                print(f"{platform}: {result.success_count} created, {result.duplicate_count} duplicates")
        else:
            platform = platform_map[args.platform]
            result = await agent.run(platform, args.channels)
            print(f"Result: {result.success_count} created, {result.duplicate_count} duplicates")

if __name__ == "__main__":
    asyncio.run(main())
```

---

## 6. ì´ë²¤íŠ¸ íë¦„ ìƒì„¸

### 6.1 Core Loop ì´ë²¤íŠ¸ ì‹œí€€ìŠ¤

```mermaid
sequenceDiagram
    autonumber
    participant User as ğŸ‘¤ User
    participant Web as ğŸŒ Web App
    participant GW as ğŸšª API Gateway
    participant Recipe as ğŸ“– Recipe Service
    participant Cookbook as ğŸ“š Cookbook Service
    participant Kafka as ğŸ“¨ Kafka
    participant AI as ğŸ¤– AI Agent
    participant Notify as ğŸ”” Notification

    Note over User, Notify: 1ï¸âƒ£ ê²€ìƒ‰ ë‹¨ê³„
    User->>Web: ë ˆì‹œí”¼ ê²€ìƒ‰
    Web->>GW: GET /api/recipes/search
    GW->>Recipe: ê²€ìƒ‰ ìš”ì²­
    Recipe-->>GW: ê²€ìƒ‰ ê²°ê³¼
    GW-->>Web: ë ˆì‹œí”¼ ëª©ë¡
    Recipe->>Kafka: RecipeSearched ì´ë²¤íŠ¸

    Note over User, Notify: 2ï¸âƒ£ ìƒì„¸ ì¡°íšŒ ë‹¨ê³„
    User->>Web: ë ˆì‹œí”¼ ì„ íƒ
    Web->>GW: GET /api/recipes/{id}
    GW->>Recipe: ìƒì„¸ ì¡°íšŒ
    Recipe-->>GW: ë ˆì‹œí”¼ ìƒì„¸
    GW-->>Web: ìƒì„¸ ì •ë³´
    Recipe->>Kafka: RecipeViewed ì´ë²¤íŠ¸

    Note over User, Notify: 3ï¸âƒ£ ì¡°ë¦¬ ì‹œì‘ ë‹¨ê³„
    User->>Web: ì¡°ë¦¬ ì‹œì‘
    Web->>GW: POST /api/cookbooks/{id}/recipes/{id}/cook
    GW->>Cookbook: ì¡°ë¦¬ ì„¸ì…˜ ì‹œì‘
    Cookbook-->>GW: ì„¸ì…˜ ì •ë³´
    GW-->>Web: ì¡°ë¦¬ ëª¨ë“œ ì§„ì…
    Cookbook->>Kafka: CookingStarted ì´ë²¤íŠ¸

    Note over User, Notify: 4ï¸âƒ£ í”¼ë“œë°± ë‹¨ê³„
    User->>Web: í”¼ë“œë°± ì…ë ¥
    Web->>GW: POST /api/cookbooks/{id}/recipes/{id}/feedback
    GW->>Cookbook: í”¼ë“œë°± ì €ì¥
    Cookbook-->>GW: ì €ì¥ ì™„ë£Œ
    GW-->>Web: í”¼ë“œë°± ì ‘ìˆ˜ í™•ì¸
    Cookbook->>Kafka: FeedbackSubmitted ì´ë²¤íŠ¸

    Note over User, Notify: 5ï¸âƒ£ AI ë³´ì • ë‹¨ê³„
    Kafka->>AI: FeedbackSubmitted ì´ë²¤íŠ¸ ìˆ˜ì‹ 
    AI->>AI: í”¼ë“œë°± ë¶„ì„
    AI->>AI: RAG ê²€ìƒ‰
    AI->>AI: ë ˆì‹œí”¼ ë³´ì •
    AI->>Kafka: AdjustmentCompleted ì´ë²¤íŠ¸
    AI->>Cookbook: ë³´ì • ê²°ê³¼ ì €ì¥

    Note over User, Notify: 6ï¸âƒ£ ì•Œë¦¼ ë° ì €ì¥ ë‹¨ê³„
    Kafka->>Notify: AdjustmentCompleted ì´ë²¤íŠ¸ ìˆ˜ì‹ 
    Notify->>Web: Push ì•Œë¦¼
    Web->>User: "ë ˆì‹œí”¼ê°€ ë³´ì •ë˜ì—ˆìŠµë‹ˆë‹¤"
    User->>Web: ë³´ì •ë³¸ í™•ì¸
    Web->>GW: GET /api/cookbooks/{id}/recipes/{id}
    GW->>Cookbook: ë³´ì •ë³¸ ì¡°íšŒ
    Cookbook-->>Web: ë³´ì •ëœ ë ˆì‹œí”¼
```

### 6.2 ì´ë²¤íŠ¸ ìŠ¤í‚¤ë§ˆ

```typescript
// ì´ë²¤íŠ¸ ê¸°ë³¸ êµ¬ì¡°
interface BaseEvent {
  eventId: string;        // UUID
  eventType: string;      // ì´ë²¤íŠ¸ ìœ í˜•
  timestamp: string;      // ISO 8601
  version: string;        // ìŠ¤í‚¤ë§ˆ ë²„ì „

  payload: object;        // ì´ë²¤íŠ¸ ë°ì´í„°

  metadata: {
    correlationId: string;  // ìš”ì²­ ì¶”ì  ID
    causationId: string;    // ì›ì¸ ì´ë²¤íŠ¸ ID
    userId?: string;        // ì‚¬ìš©ì ID
    sessionId?: string;     // ì„¸ì…˜ ID
  };
}

// í”¼ë“œë°± ì œì¶œ ì´ë²¤íŠ¸
interface FeedbackSubmittedEvent extends BaseEvent {
  eventType: 'FeedbackSubmitted';

  payload: {
    cookbookRecipeId: string;
    versionId: string;
    feedback: {
      tasteRating: number;
      difficultyRating: number;
      feedbackText: string;
      adjustmentRequests: Array<{
        category: 'taste' | 'portion' | 'difficulty' | 'ingredient';
        description: string;
      }>;
    };
    cookingDurationMinutes: number;
  };
}

// AI ë³´ì • ì™„ë£Œ ì´ë²¤íŠ¸
interface AdjustmentCompletedEvent extends BaseEvent {
  eventType: 'AdjustmentCompleted';

  payload: {
    adjustmentRequestId: string;
    cookbookRecipeId: string;
    newVersionId: string;
    changeSummary: string;
    adjustmentDetails: {
      ingredientChanges: Array<{
        type: 'modified' | 'added' | 'removed';
        name: string;
        originalValue?: string;
        newValue?: string;
      }>;
      stepChanges: Array<{
        stepNumber: number;
        changeType: 'modified' | 'added' | 'removed';
        description: string;
      }>;
    };
    processingTimeMs: number;
    modelUsed: string;
  };
}

// ì¡°ë¦¬ ì™„ë£Œ ì´ë²¤íŠ¸
interface CookingCompletedEvent extends BaseEvent {
  eventType: 'CookingCompleted';

  payload: {
    cookbookRecipeId: string;
    versionId: string;
    actualDurationMinutes: number;
    completedSteps: number;
    totalSteps: number;
  };
}
```

---

## 6. ë²¡í„° ê²€ìƒ‰ (RAG) ì•„í‚¤í…ì²˜

### 6.1 ì„ë² ë”© íŒŒì´í”„ë¼ì¸

```mermaid
flowchart TB
    subgraph Sources["ë°ì´í„° ì†ŒìŠ¤"]
        S1[ë ˆì‹œí”¼ ë°ì´í„°]
        S2[ìš”ë¦¬ íŒ/ì§€ì‹]
        S3[ì¬ë£Œ ì •ë³´]
        S4[ì‚¬ìš©ì í”¼ë“œë°±]
    end

    subgraph Processing["ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸"]
        P1[ì²­í‚¹<br/>Chunking]
        P2[ë©”íƒ€ë°ì´í„° ì¶”ì¶œ]
        P3[ì„ë² ë”© ìƒì„±<br/>OpenAI ada-002]
    end

    subgraph Storage["ì €ì¥ì†Œ"]
        VS[(pgvector<br/>Vector Store)]
    end

    subgraph Retrieval["ê²€ìƒ‰"]
        R1[ì¿¼ë¦¬ ì„ë² ë”©]
        R2[ìœ ì‚¬ë„ ê²€ìƒ‰<br/>Cosine Similarity]
        R3[ë¦¬ë­í‚¹]
        R4[ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±]
    end

    Sources --> P1
    P1 --> P2
    P2 --> P3
    P3 --> VS

    VS --> R2
    R1 --> R2
    R2 --> R3
    R3 --> R4
```

### 6.2 ì²­í‚¹ ì „ëµ

```python
# chunking_strategy.py

from langchain.text_splitter import RecursiveCharacterTextSplitter
from typing import List, Dict

class RecipeChunker:
    """ë ˆì‹œí”¼ ë°ì´í„° ì²­í‚¹ ì „ëµ"""

    def __init__(self):
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=500,
            chunk_overlap=50,
            separators=["\n\n", "\n", ". ", " "]
        )

    def chunk_recipe(self, recipe: Dict) -> List[Dict]:
        """ë ˆì‹œí”¼ë¥¼ ê²€ìƒ‰ ê°€ëŠ¥í•œ ì²­í¬ë¡œ ë¶„ë¦¬"""
        chunks = []

        # 1. ë ˆì‹œí”¼ ê°œìš” ì²­í¬
        overview_chunk = {
            "source_type": "recipe_overview",
            "source_id": recipe["id"],
            "content": f"""
                ë ˆì‹œí”¼: {recipe["title"]}
                ì„¤ëª…: {recipe["description"]}
                ë‚œì´ë„: {recipe["difficulty"]}
                ì†Œìš”ì‹œê°„: {recipe["cooking_time_minutes"]}ë¶„
                ì¸ë¶„: {recipe["servings"]}ì¸ë¶„
            """,
            "metadata": {
                "recipe_id": recipe["id"],
                "title": recipe["title"],
                "chunk_type": "overview"
            }
        }
        chunks.append(overview_chunk)

        # 2. ì¬ë£Œ ì²­í¬
        ingredients_text = "\n".join([
            f"- {ing['name']}: {ing['amount']} {ing['unit']}"
            for ing in recipe["ingredients"]
        ])
        ingredients_chunk = {
            "source_type": "recipe_ingredients",
            "source_id": recipe["id"],
            "content": f"ë ˆì‹œí”¼ '{recipe['title']}'ì˜ ì¬ë£Œ:\n{ingredients_text}",
            "metadata": {
                "recipe_id": recipe["id"],
                "title": recipe["title"],
                "chunk_type": "ingredients"
            }
        }
        chunks.append(ingredients_chunk)

        # 3. ì¡°ë¦¬ ë‹¨ê³„ ì²­í¬ (2-3ë‹¨ê³„ì”© ê·¸ë£¹)
        steps = recipe["steps"]
        for i in range(0, len(steps), 2):
            step_group = steps[i:i+2]
            steps_text = "\n".join([
                f"{s['step_number']}. {s['instruction']}"
                for s in step_group
            ])
            step_chunk = {
                "source_type": "recipe_steps",
                "source_id": recipe["id"],
                "content": f"ë ˆì‹œí”¼ '{recipe['title']}' ì¡°ë¦¬ ë‹¨ê³„:\n{steps_text}",
                "metadata": {
                    "recipe_id": recipe["id"],
                    "title": recipe["title"],
                    "chunk_type": "steps",
                    "step_range": f"{step_group[0]['step_number']}-{step_group[-1]['step_number']}"
                }
            }
            chunks.append(step_chunk)

        return chunks
```

---

## 7. LLM ì—°ë™ ë° ì¥ì•  ëŒ€ì‘

### 7.1 LLM ì—°ë™ ì„¤ì •

```python
# llm_config.py

from langchain_openai import ChatOpenAI
from langchain_anthropic import ChatAnthropic
from tenacity import retry, stop_after_attempt, wait_exponential

class LLMManager:
    """LLM ì—°ë™ ê´€ë¦¬"""

    def __init__(self):
        self.primary = ChatOpenAI(
            model="gpt-4-turbo-preview",
            temperature=0.3,
            max_tokens=2000,
            request_timeout=30
        )

        self.fallback = ChatAnthropic(
            model="claude-3-sonnet-20240229",
            temperature=0.3,
            max_tokens=2000
        )

        self.fast = ChatOpenAI(
            model="gpt-3.5-turbo",
            temperature=0.3,
            max_tokens=1000,
            request_timeout=10
        )

    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=1, max=10)
    )
    async def invoke_with_fallback(self, prompt: str) -> str:
        """Primary LLM í˜¸ì¶œ, ì‹¤íŒ¨ ì‹œ Fallback"""
        try:
            response = await self.primary.ainvoke(prompt)
            return response.content
        except Exception as e:
            # Log primary failure
            logger.warning(f"Primary LLM failed: {e}")

            try:
                response = await self.fallback.ainvoke(prompt)
                return response.content
            except Exception as fallback_error:
                logger.error(f"Fallback LLM also failed: {fallback_error}")
                raise
```

### 7.2 ë¹„ìš© ê´€ë¦¬

| ëª¨ë¸ | ìš©ë„ | Input Cost | Output Cost | ì¼ ì˜ˆìƒ í˜¸ì¶œ | ì›” ì˜ˆìƒ ë¹„ìš© |
|------|------|-----------|-------------|-------------|-------------|
| GPT-4 Turbo | Adjustment, Q&A | $10/1M | $30/1M | 5,000 | ~$1,500 |
| Claude 3 Sonnet | Fallback | $3/1M | $15/1M | 500 | ~$100 |
| GPT-3.5 Turbo | ë¶„ë¥˜, íƒœê¹… | $0.5/1M | $1.5/1M | 20,000 | ~$50 |
| ada-002 | Embedding | $0.1/1M | - | 50,000 | ~$5 |

---

## ë³€ê²½ ì´ë ¥

| ë²„ì „ | ë‚ ì§œ | ë³€ê²½ ë‚´ìš© |
|-----|------|----------|
| v1.0 | 2025.11.30 | ì´ˆê¸° ë¬¸ì„œ ì‘ì„± |

---

> **ì´ì „ ë¬¸ì„œ:** [5-1-2_SYSTEM.md](./5-1-2_SYSTEM.md) - ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜
> **ë‹¤ìŒ ë¬¸ì„œ:** [5-1-4_API.md](./5-1-4_API.md) - API ì„¤ê³„
